{
  "full_patchscribe_c4": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.6082474226804123,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 38,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 1,
          "logical_consistency": 24,
          "completeness": 19
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.0859106529209622,
        "avg_accuracy_score": 3.11,
        "avg_clarity_score": 2.884,
        "avg_causality_score": 3.016
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.0859106529209622,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.6082474226804123,
      "triple_verification_pass_rate": 0.6082474226804123,
      "avg_llm_accuracy": 3.1100000000000003,
      "avg_llm_clarity": 2.884,
      "avg_llm_causality": 3.0159999999999996
    }
  },
  "baseline_c1": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.0,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 0,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 0,
          "logical_consistency": 0,
          "completeness": 0
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.2027491408934708,
        "avg_accuracy_score": 3.696875,
        "avg_clarity_score": 3.36875,
        "avg_causality_score": 3.815625
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.20274914089347076,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.0,
      "triple_verification_pass_rate": 0.0,
      "avg_llm_accuracy": 3.6968750000000004,
      "avg_llm_clarity": 3.36875,
      "avg_llm_causality": 3.8156250000000003
    }
  },
  "prehoc_c3": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.0,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 0,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 0,
          "logical_consistency": 0,
          "completeness": 0
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.09278350515463916,
        "avg_accuracy_score": 4.322222222222222,
        "avg_clarity_score": 3.7351851851851854,
        "avg_causality_score": 4.007407407407407
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.09278350515463915,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.0,
      "triple_verification_pass_rate": 0.0,
      "avg_llm_accuracy": 4.322222222222222,
      "avg_llm_clarity": 3.735185185185185,
      "avg_llm_causality": 4.007407407407407
    }
  },
  "vague_hints_c2": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.0,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 0,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 0,
          "logical_consistency": 0,
          "completeness": 0
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.18041237113402062,
        "avg_accuracy_score": 4.154761904761905,
        "avg_clarity_score": 3.6809523809523808,
        "avg_causality_score": 3.9166666666666665
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.18041237113402053,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.0,
      "triple_verification_pass_rate": 0.0,
      "avg_llm_accuracy": 4.154761904761905,
      "avg_llm_clarity": 3.6809523809523808,
      "avg_llm_causality": 3.916666666666666
    }
  }
}