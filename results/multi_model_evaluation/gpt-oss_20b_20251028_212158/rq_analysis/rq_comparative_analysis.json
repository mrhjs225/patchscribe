{
  "full_patchscribe_c4": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.6701030927835051,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 32,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 4,
          "logical_consistency": 13,
          "completeness": 21
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.4209621993127148,
        "avg_accuracy_score": 4.0237113402061855,
        "avg_clarity_score": 4.089690721649484,
        "avg_causality_score": 4.241237113402062
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.420962199312715,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.6701030927835051,
      "triple_verification_pass_rate": 0.6701030927835051,
      "avg_llm_accuracy": 4.0237113402061855,
      "avg_llm_clarity": 4.089690721649484,
      "avg_llm_causality": 4.241237113402062
    }
  },
  "baseline_c1": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.0,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 0,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 0,
          "logical_consistency": 0,
          "completeness": 0
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.46048109965635736,
        "avg_accuracy_score": 3.685567010309278,
        "avg_clarity_score": 4.118556701030927,
        "avg_causality_score": 4.15979381443299
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.46048109965635753,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.0,
      "triple_verification_pass_rate": 0.0,
      "avg_llm_accuracy": 3.685567010309278,
      "avg_llm_clarity": 4.118556701030927,
      "avg_llm_causality": 4.15979381443299
    }
  },
  "prehoc_c3": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.0,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 0,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 0,
          "logical_consistency": 0,
          "completeness": 0
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.41237113402061853,
        "avg_accuracy_score": 3.971134020618557,
        "avg_clarity_score": 4.116494845360824,
        "avg_causality_score": 4.167010309278351
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.41237113402061887,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.0,
      "triple_verification_pass_rate": 0.0,
      "avg_llm_accuracy": 3.971134020618557,
      "avg_llm_clarity": 4.116494845360825,
      "avg_llm_causality": 4.167010309278351
    }
  },
  "vague_hints_c2": {
    "rq1_theory_guided_generation": [
      {
        "condition": "unknown",
        "triple_verification_rate": 0.0,
        "ground_truth_similarity": 1.0,
        "first_attempt_success_rate": 0.0,
        "total_cases": 97
      }
    ],
    "rq2_dual_verification": [
      {
        "verification_method": "Triple Verification (V4)",
        "incomplete_patches_caught": 0,
        "precision": 0.0,
        "recall": 0.0,
        "consistency_violations": {
          "causal_coverage": 0,
          "intervention_validity": 0,
          "logical_consistency": 0,
          "completeness": 0
        }
      }
    ],
    "rq3_scalability_performance": [],
    "rq4_explanation_quality": [
      {
        "explanation_type": "Dual Explanations (E_bug + E_patch)",
        "checklist_coverage": 0.436426116838488,
        "avg_accuracy_score": 3.711340206185567,
        "avg_clarity_score": 4.028865979381443,
        "avg_causality_score": 4.032989690721649
      }
    ],
    "overall_metrics": {
      "total_cases": 97.0,
      "success_rate": 1.0,
      "expectation_match_rate": 1.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 0.0,
      "vulnerability_elimination_rate": 0.7731958762886598,
      "ground_truth_match_rate": 1.0,
      "avg_explanation_checklist": 0.436426116838488,
      "first_attempt_success_rate": 0.0,
      "consistency_pass_rate": 0.0,
      "triple_verification_pass_rate": 0.0,
      "avg_llm_accuracy": 3.711340206185567,
      "avg_llm_clarity": 4.028865979381443,
      "avg_llm_causality": 4.032989690721649
    }
  }
}